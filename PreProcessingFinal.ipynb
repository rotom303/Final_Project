{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNX7tzcc5DC/mgelOKh6ztu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rotom303/Final_Project/blob/main/PreProcessingFinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finger Flexion Final Project\n",
        "Developed by\n",
        "\n",
        "Alexander Byrd, Aakash Jajoo, Chaoyi Cheng\n",
        "\n"
      ],
      "metadata": {
        "id": "NkOTH7Mtn2am"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Setup"
      ],
      "metadata": {
        "id": "8v4jHpYSoEnu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2ragnF2mobl",
        "outputId": "57fd5728-d39e-4221-fbeb-3e2722e87e8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deepdiff\n",
            "  Downloading deepdiff-6.3.0-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ordered-set<4.2.0,>=4.0.2\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: ordered-set, deepdiff\n",
            "Successfully installed deepdiff-6.3.0 ordered-set-4.1.0\n"
          ]
        }
      ],
      "source": [
        "#Set up the notebook environment\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from scipy.stats import pearsonr\n",
        "from scipy import signal as sig\n",
        "from scipy.io import loadmat, savemat\n",
        "from scipy.fft import fft, fftfreq\n",
        "import random\n",
        "from google.colab import drive\n",
        "\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from google.auth import default\n",
        "\n",
        "!pip install deepdiff\n",
        "from deepdiff import DeepDiff\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**File Directory:**\n"
      ],
      "metadata": {
        "id": "btuAY3-7oP1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Brain_Computer_Interfaces/Final_Project/\n",
        "\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "proj_data = loadmat('raw_training_data.mat')\n",
        "leaderboard_data = loadmat('leaderboard_data.mat')\n",
        "fs = 1000 # Sampling frequency of the signals\n",
        "numPatients = 3 # This is just to increase reusability."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Sjs6zAZocE_",
        "outputId": "94927824-9d9a-4d08-d6af-32e63c3cdf7f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Brain_Computer_Interfaces/Final_Project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filter Design\n"
      ],
      "metadata": {
        "id": "eRSs2D-zoqGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Filter parameters:\n",
        "\n",
        "fc_passband: a list in form [f1,f2]. f1 and f2 are the corner frequencies of\n",
        "  a bandpass filter (-3dB attenuation at f1 & f2). Frequencies in between f1 and \n",
        "  f2 are kept (called the pass band) while others outside that range are \n",
        "  attenuated (called the rejection band). Units = Hz \n",
        "\n",
        "order: The order of the bandpass filter used. Increasing the order of a filter\n",
        "  makes the transition between the pass band and the rejection band sharper. In\n",
        "  the case of a Butterworth filter, increasing order means the pass band stays\n",
        "  flat closer to f1 and f2. Increasing the order too much will reduce filter \n",
        "  stability and can result in ripples in the pass band or other unpredictable\n",
        "  behaviour. 4th to 6th Order filters tend to be the best compromise.  \n",
        "\n",
        "applyNotch: a Boolean for whether or not to apply a notch filter. A Notch filter\n",
        "  Removes noise at precise frequencies. It is useful for removing artifacts\n",
        "  from power supplies, which are usually at harmonics of 60Hz.   \n",
        "\n",
        "f_notch: Selects the frequencies which are removed with a Notch Filter. It must\n",
        "  be a list, even if it just has 1 element. Units = Hz.\n",
        "\n",
        "Q: is the quality factor of the notch filter. A low Q will also attenuate\n",
        "  frequencies near f_notch. A high Q will make the notch filter more precise, \n",
        "  but it will not attenuate f_notch as much. \n",
        "\"\"\"\n",
        "fc_passband = [75,115]\n",
        "order = 4\n",
        "applyNotch = True \n",
        "f_notch = [60,120]; \n",
        "Q = 50\n",
        "\n",
        "def apply_filter(raw_signal):\n",
        "  \"\"\"\n",
        "  Input: \n",
        "    raw_signal (samples x channels): the raw signal\n",
        "  Output: \n",
        "    clean_data (samples x channels): the filtered signal\n",
        "  \"\"\"\n",
        "  number_of_channels = np.shape(raw_signal)[1] #number of channels\n",
        "  filteredData = np.zeros(np.shape(raw_signal)); #filtered data output\n",
        "\n",
        "  # Bandpass Butterworth filter \n",
        "  sos = sig.butter(order, fc_passband, 'bandpass', analog=False, fs=fs, output='sos'); # returns filter coefficients\n",
        "  b_notch = []; a_notch = []\n",
        "  for f_remove in f_notch:\n",
        "    b, a = sig.iirnotch(f_remove,Q,fs=fs)\n",
        "    b_notch.append(b); a_notch.append(a)\n",
        "  #for each channel\n",
        "  for chanInd in np.arange(number_of_channels):\n",
        "    # subtract mean from each datapoint\n",
        "    currFilt = raw_signal[:, chanInd] - np.mean(raw_signal[:, chanInd]);\n",
        "    if(applyNotch): \n",
        "      for i in range(len(b_notch)):\n",
        "        currFilt = sig.filtfilt(b_notch[i],a_notch[i],currFilt)\n",
        "    currFilt = sig.sosfiltfilt(sos, currFilt) # forward-backward digital filter using cascaded second-order sections                                        \n",
        "    filteredData[:, chanInd] = currFilt\n",
        "  return filteredData"
      ],
      "metadata": {
        "id": "PV8onTEvpNyu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction"
      ],
      "metadata": {
        "id": "Lsp4l6bZowqG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Class\n",
        "Every feature is a child of this class. This class streamlines the process of adding features and how we take extract them from the ECoG data. We can easily change whether a feature is normalized (using standardization method) and whether it uses the raw or filtered ECoG data. \n",
        "This class will save the mean and standard deviation of the training data so it can easily standardize both training and testing data.\n",
        "\n",
        "We can define every feature we consider here, but the only features that are extracted and used in the models will be the ones we instantiate as objects. Every object we instantiate is automatically added to the global list *featFns*, which keeps track of the features we are analyzing. "
      ],
      "metadata": {
        "id": "t1Q4qzPX3CPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global featFns;\n",
        "featFns = [] # A list that stores all the Feature Objects used\n",
        "featDict = dict() # a dict that stores each Feature Object. \n",
        "  # The dict keys are from its get_name method.\n",
        "\n",
        "class Feature():\n",
        "  def __init__(self,isFiltered=True, doNormalize=True):\n",
        "    self.isFiltered = isFiltered # Whether or not the feature is extracted from the raw or filtered data.\n",
        "    self.doNormalize = doNormalize # Whether or not to normalize this feature\n",
        "    self.mean = 0 # mean\n",
        "    self.std = 1 # standard deviation\n",
        "    featFns.append(self)\n",
        "\n",
        "  def __call__(self, signal_data):\n",
        "    return signal_data\n",
        "\n",
        "  def get_name(self,nameAddon=None):\n",
        "    name = type(self).__name__\n",
        "    if nameAddon is not None:\n",
        "      name += nameAddon\n",
        "    name_filter = 'Filtered'\n",
        "    name_norm = 'Normalized'\n",
        "    if not self.isFiltered: name_filter = 'not' + name_filter\n",
        "    if not self.doNormalize: name_norm = 'not' + name_norm\n",
        "    fullname = name + '_' + name_filter + '_' + name_norm\n",
        "    featDict[fullname] = self\n",
        "    return fullname\n",
        "\n",
        "  def standardize_training(self,training_feat):\n",
        "    if(self.doNormalize):\n",
        "      self.mean = np.mean(training_feat)\n",
        "      self.std = np.std(training_feat)\n",
        "    return (training_feat - self.mean)/self.std\n",
        "\n",
        "  def standardize_testing(self,testing_feat):\n",
        "    return (testing_feat-self.mean) / self.std\n",
        "  \n"
      ],
      "metadata": {
        "id": "zaJSPNcPpEGn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Definitions\n",
        "This is where the functions for the different features are defined. The functions themselves should be written in the __ call__(self, window) method.\n",
        "\n",
        "Note that the functions are applied to one window in one channel at a time. "
      ],
      "metadata": {
        "id": "kbCjx0dXHqKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LineLength(Feature):\n",
        "  def __call__(self,x):\n",
        "    return np.sum(np.absolute(np.ediff1d(x)))\n",
        "\n",
        "class Area(Feature):\n",
        "  def __call__(self,x):\n",
        "    return np.sum(np.absolute(x))\n",
        "\n",
        "class Energy(Feature):\n",
        "  def __call__(self,x):\n",
        "    return np.sum(np.square(x))\n",
        "\n",
        "class ZeroCrossings(Feature):\n",
        "  def __call__(self,x):\n",
        "    return np.size(np.nonzero(np.ediff1d(np.sign(x-np.mean(x)))))\n",
        "\n",
        "class Mean(Feature):\n",
        "  def __call__(self,x):\n",
        "    return np.mean(x)\n",
        "\n",
        "class FreqBand(Feature):\n",
        "  def __init__(self,f_low,f_high,isFiltered=False,doNormalize=True):\n",
        "    Feature.__init__(self,isFiltered,doNormalize)\n",
        "    self.f_low = f_low\n",
        "    self.f_high = f_high\n",
        "  \n",
        "  def __call__(self,signal):\n",
        "    freq_response = fft(signal)\n",
        "    N = len(freq_response)\n",
        "    n = np.arange(N)\n",
        "    T = N/fs #sampling rate=1000\n",
        "    freq = n/T \n",
        "    power_spectrum = np.abs(freq_response)\n",
        "    # Find values in frequency vector corresponding to input band\n",
        "    index_band = np.logical_and(freq >= self.f_low, freq <= self.f_high)\n",
        "    #average frequency domain magnitude\n",
        "    avg_mag = np.mean(power_spectrum[index_band])\n",
        "    return avg_mag\n",
        "\n",
        "  def get_name(self):\n",
        "    nameAddon = str(self.f_low) + 'to' + str(self.f_high)\n",
        "    return Feature.get_name(self,nameAddon)"
      ],
      "metadata": {
        "id": "59khQQ-oHq8M"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Windowed Feats"
      ],
      "metadata": {
        "id": "nS6g6VTP4Ry2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NumWins(x,winLen,winDisp,fs=1000):\n",
        "  \"\"\"\n",
        "    Calculates the number of possible full windows that can fit in x\n",
        "    Inputs:\n",
        "      x is the signal in the time domain. \n",
        "      fs is the sampling frequency of x. Hz.\n",
        "      winLen is the length of windows. sec\n",
        "      winDisp is the displacement between the start of each window. sec\n",
        "  \"\"\"\n",
        "  x_duration = len(x)/fs # seconds.\n",
        "  windows_fit = (x_duration - winLen + winDisp) / (winDisp)\n",
        "  # default behaviour of int() is to floor float, so using round()\n",
        "  return round(windows_fit)\n",
        "\n",
        "def get_features(raw_window,filtered_window):\n",
        "  \"\"\"\n",
        "    Input: \n",
        "      raw_window (window_samples x channels): the window of the unfiltered ecog signal \n",
        "      filtered_window (window_samples x channels): the window of the filtered ecog signal \n",
        "      \n",
        "\n",
        "    Global Inputs: must be defined outside of the function\n",
        "      featFns: a list containing the methods to apply as feats. \n",
        "    \n",
        "    Output:s\n",
        "      features (channels x num_features): the features calculated on each channel for the window\n",
        "  \"\"\"\n",
        "  [window_samples,num_channels]=np.shape(raw_window)\n",
        "  features=np.empty((num_channels,len(featFns)))\n",
        "  i = 0\n",
        "  for feat in featFns:\n",
        "    if feat.isFiltered: window = filtered_window\n",
        "    else: window = raw_window\n",
        "    for chn in range(num_channels):\n",
        "      current_window = window[:,chn]\n",
        "      features[chn,i] = feat(current_window)\n",
        "    i+=1\n",
        "  return features\n",
        "\n",
        "def get_windowed_feats(ecog_data, window_length, window_overlap):\n",
        "  \"\"\"\n",
        "    Inputs:\n",
        "      raw_eeg (samples x channels): the raw signal\n",
        "      window_length: the window's length\n",
        "      window_overlap: the window's overlap\n",
        "    Output: \n",
        "      all_feats (num_windows x (channels x features)): the features for each channel for each time window\n",
        "        note that this is a 2D array. \n",
        "  \"\"\"\n",
        "  [num_samples,num_channels]=np.shape(ecog_data)\n",
        "  num_windows = NumWins(ecog_data, window_length,window_overlap, fs) \n",
        "  filtered_ecog = apply_filter(ecog_data)\n",
        "  #convert everything to units of samples\n",
        "  wLen=round(window_length*fs) #window length in samples\n",
        "  wDisp=round(window_overlap*fs) #window displacement in samples\n",
        "  data_feats = np.zeros((num_windows,num_channels*len(featFns))); # stores the features of the window\n",
        "   \n",
        "   \n",
        "  rightmost = num_samples\n",
        "  for i in range(num_windows):\n",
        "    raw_window = ecog_data[rightmost-wLen:rightmost,:]\n",
        "    filtered_window = filtered_ecog[rightmost-wLen:rightmost,:]\n",
        "    data_feats[-1-i,:] = (get_features(raw_window,filtered_window).flatten())\n",
        "    rightmost = rightmost - wDisp\n",
        "  return data_feats\n"
      ],
      "metadata": {
        "id": "eg6MkCDg5Csq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Normalization\n",
        "We are using standardization to normalize every feature.\n",
        ":"
      ],
      "metadata": {
        "id": "WP_6_JBw4Xd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def standardize_training(feature_matrix):\n",
        "  [windows_trn,feats_trn] = np.shape(feature_matrix)\n",
        "  normFeats = np.empty((windows_trn,feats_trn))\n",
        "  for i in range(feats_trn):\n",
        "      normFeats[:,i] = featFns[i].standardize_training(feature_matrix)\n",
        "  return normFeats\n",
        "\n",
        "def standardize_testing(feature_matrix):\n",
        "  [windows_trn,feats_trn] = np.shape(feature_matrix)\n",
        "  normFeats = np.empty((windows_trn,feats_trn))\n",
        "  for i in range(feats_trn):\n",
        "      normFeats[:,i] = featFns[i].standardize_testing(feature_matrix)\n",
        "  return normFeats\n",
        "\n",
        "def standardize_both(train_feats, test_feats):\n",
        "  return standardize_training(train_feats), standardize_testing(test_feats)"
      ],
      "metadata": {
        "id": "S-ntPeP04bOd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Response Matrix\n",
        "We will be using a response matrix as the input to each of our learning algorithms. This is because it allows us to associate one window with the *N_wind* windows before it instead of treating each window as an independent case.   "
      ],
      "metadata": {
        "id": "m_qSn_Au4uE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_R_matrix(features, N_wind):\n",
        "  \"\"\" \n",
        "  Input:\n",
        "    features (samples (number of windows in the signal) x channels x features): \n",
        "      the features you calculated using get_windowed_feats\n",
        "    N_wind: number of windows to use in the R matrix\n",
        "\n",
        "  Output:\n",
        "    R (samples x (N_wind*channels*features))\n",
        "  \"\"\"\n",
        "  features_appended = np.copy(features)\n",
        "  for i in list(range(N_wind-2, -1, -1)):\n",
        "      a = features[i]\n",
        "      features_appended = np.vstack([a, features_appended])\n",
        "  samples = len(features)   # number of rows = number of windows\n",
        "\n",
        "  R = np.zeros((samples, 1+(N_wind*len(features[0,:]))))  # len(features[0,:]) = (num of features)*(num of channels)\n",
        "  lst = np.array(list(range(1, 1+N_wind)))\n",
        "  R[:, 0] = 1\n",
        "  \n",
        "  \n",
        "  for i in range(len(features[0,:])):   # goes thru each column of the features matrix\n",
        "    for j in range(len(lst)):\n",
        "        x = lst[j]\n",
        "        R[:, x] = features_appended[j : (len(features_appended)-(N_wind-1-j)), i]\n",
        "    lst = lst + N_wind\n",
        "  return R\n"
      ],
      "metadata": {
        "id": "Y8d0IL7L43EH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Parameters"
      ],
      "metadata": {
        "id": "ZCGpfarf6r8H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## User-Defined Parameters\n",
        "Below are the user defined parameters. All the parameters are defined here, except for the ones that have already been defined for the filter in the Filter Design section."
      ],
      "metadata": {
        "id": "AYi9mZrltChU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Name of the file to write or read the data from for parameters and R matrices\n",
        "filename = 'previousRun.pkl'\n",
        "use_file_params = False \n",
        "# If use_file_params is True, then it will overwrite the parameters defined here\n",
        "\n",
        "# Window Parameters\n",
        "window_length = 100e-3  # seconds\n",
        "window_displacement = 50e-3 #seconds\n",
        "N_winds = 3 # Number of previous windows considered in Response matrix. \n",
        "\n",
        "# These Booleans are to make code clearer\n",
        "uses_raw = False; uses_filtered = True \n",
        "not_normalized = False; normalized = True; \n",
        "# Different Features analyzed\n",
        "line_length = LineLength(uses_filtered,normalized)\n",
        "area = Area(uses_filtered,normalized)\n",
        "energy = Energy(uses_filtered,normalized)\n",
        "zero_crossings = ZeroCrossings(uses_filtered,normalized)\n",
        "mean = Mean(uses_filtered,normalized)\n",
        "freq_band_5_to_15 = FreqBand(5,15,uses_raw,normalized)\n",
        "freq_band_20_to_25 = FreqBand(20,25,uses_raw,normalized)\n",
        "freq_band_75_to_115 = FreqBand(75,115,uses_raw,normalized)\n",
        "freq_band_125_to_160 = FreqBand(125,160,uses_raw,normalized)\n",
        "freq_band_160_to_175 = FreqBand(160,175,uses_raw,normalized)\n",
        "\n",
        "# Training / Testing Split\n",
        "training_fraction = 2/3 # What fraction of the samples\n"
      ],
      "metadata": {
        "id": "3xT8HfGK6vsD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameter Dictionary\n",
        "Here we put all the parameters into a dictionary. This makes it easy to export them and compare them between trials. This dictionary will be compared to parameter dictionaries from previous trials, and if they use the same parameters, we will just load the previous feature and R matrices instead of calculating them all again. The saving and loading code is towards the end of the Preparing Data section."
      ],
      "metadata": {
        "id": "79zFtNHr0Gtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global param_dict;\n",
        "param_dict = dict()\n",
        "# Filter Params\n",
        "param_dict['fs'] = fs\n",
        "param_dict['fc_passband'] = fc_passband \n",
        "param_dict['order'] = order\n",
        "param_dict['applyNotch'] = applyNotch\n",
        "param_dict['f_notch'] = f_notch\n",
        "param_dict['Q'] = Q\n",
        "# Window Parameters\n",
        "param_dict['winLen'] = window_length\n",
        "param_dict['winDisp'] = window_displacement\n",
        "param_dict['N_winds'] = N_winds\n",
        "# Feature Parameters\n",
        "param_dict['featFns'] = []\n",
        "for feat in featFns:\n",
        "  param_dict['featFns'].append(feat.get_name())\n",
        "# Training / Testing Split Parameter\n",
        "param_dict['training_fraction'] = training_fraction\n"
      ],
      "metadata": {
        "id": "JGge8-zh0jhQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n",
        "Putting the data in a form that can be easily used for different learning algorithms. "
      ],
      "metadata": {
        "id": "lEp6hxF9ozMl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helpful Functions"
      ],
      "metadata": {
        "id": "jBIEoe-8z1m8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(data, train_fraction = training_fraction):\n",
        "  \"\"\"\n",
        "    Inputs:\n",
        "    data = a samples x channels array of data for one patient\n",
        "    training_fraction = a number between 0 and 1 that represents the fraction of\n",
        "      data that will be put into the training split. The remaining will be put\n",
        "      into the testing split. \n",
        "    Returns:\n",
        "      training data, testing data\n",
        "  \"\"\"\n",
        "  m = len(data[:,0]) # Number of samples per channel\n",
        "  m_training = round(train_fraction*m)\n",
        "  training_data = data[0:m_training,:]\n",
        "  testing_data = data[m_training:-1,:]\n",
        "  return training_data, testing_data\n",
        "\n",
        "def save_feature_parameters(filename):  \n",
        "  with open(filename, 'wb') as f:\n",
        "    # Note that this will overwrite any data already in filename\n",
        "    pickle.dump(param_dict,f)\n",
        "  print(f\"The parameters and R matrices have been saved in {filename}\")\n",
        "\n",
        "def load_feature_parameters(filename):\n",
        "  with open(filename, 'rb') as f:\n",
        "    ref_dict = pickle.load(f)\n",
        "  return ref_dict\n",
        "\n",
        "def compare_dicts(dict1,dict2):\n",
        "  \"\"\"\n",
        "    Input: dict1 and dict2 are borth dictionaries. The expectation is that they\n",
        "      have the same keys. \n",
        "    Returns: the number of differences between the keys in dict1 and the keys in\n",
        "      dict2. It will also print them out.  \n",
        "  \"\"\"\n",
        "  differences = DeepDiff(dict1,dict2)\n",
        "  num_differences = len(differences.to_dict())\n",
        "  if num_differences > 0:\n",
        "    print(f'{filename} uses different parameters from the ones currently set.')\n",
        "    print(differences)\n",
        "  return num_differences"
      ],
      "metadata": {
        "id": "FrE3qg7l0w7N"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "3ugGr1xSzUbq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is where all the R Matrices are either loaded or created depending on whether the filename provided has them already. If it does not, then the newly created R matrices will be saved into it. "
      ],
      "metadata": {
        "id": "-z3QgG4EToOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_ecog = proj_data['train_ecog'][:,0]\n",
        "raw_glove = proj_data['train_dg'][:,0]\n",
        "raw_leaderboard = leaderboard_data['leaderboard_ecog'][:,0]\n"
      ],
      "metadata": {
        "id": "3ec3JILB1P58"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newDataNeeded = True \n",
        "# new Data Needed is True by default, but set to False if data matching the\n",
        "# parameters described in param_dict are found in filename. \n",
        "\n",
        "try: # This Try-Except block is in case filename does not exist\n",
        "  ref_dict = load_feature_parameters(filename)\n",
        "  # featwinds_total = ref_dict.pop('featwinds_total',None)\n",
        "  # featwinds_training = ref_dict.pop('featwinds_training',None)\n",
        "  # featwinds_testing = ref_dict.pop('featwinds_testing',None)\n",
        "  # featwinds_leaderboard = ref_dict.pop('featwinds_leaderboard',None)\n",
        "  R_total = ref_dict.pop('R_total',None)\n",
        "  R_train = ref_dict.pop('R_train',None)\n",
        "  R_test = ref_dict.pop('R_test',None)\n",
        "  R_leaderboard = ref_dict.pop('R_leaderboard',None) \n",
        "  if compare_dicts(param_dict, ref_dict) == 0:\n",
        "    newDataNeeded = False\n",
        "    print(f\"{filename} uses the same parameters as currently set, so it will be loaded\")\n",
        "  elif use_file_params:\n",
        "    newDataNeeded = False\n",
        "    print(f\"{filename} uses different parameters, but use_file_params is True\")\n",
        "except: \n",
        "  print(f'{filename} was not found. Creating new a dataset instead')\n",
        "finally:\n",
        "  if newDataNeeded:\n",
        "    # featwinds_total = []; featwinds_leaderboard = []\n",
        "    # featwinds_training = []; featwinds_testing = []\n",
        "    #glove_flexion_total = []\n",
        "    R_total = []; R_leaderboard = []; R_train = []; R_test = []\n",
        "    for p in range(numPatients):\n",
        "      feat_matrix_p = get_windowed_feats(raw_ecog[p], window_length, window_displacement)\n",
        "      R_total.append(create_R_matrix(feat_matrix_p,N_winds))\n",
        "      \n",
        "      leaderboard_feats = get_windowed_feats(raw_leaderboard[p], window_length, window_displacement)\n",
        "      R_leaderboard.append(create_R_matrix(leaderboard_feats,N_winds))\n",
        "\n",
        "      trn_matrix_p, tst_matrix_p = split_data(feat_matrix_p)\n",
        "      R_train.append(create_R_matrix(trn_matrix_p,N_winds))\n",
        "      R_test.append(create_R_matrix(tst_matrix_p,N_winds))\n",
        "\n",
        "      # glove_flexion_total.append(downsample(raw_glove[p]))\n",
        "      # featwinds_total.append(feat_matrix_p)\n",
        "      # featwinds_training.append(trn_matrix_p); \n",
        "      # featwinds_testing.append(tst_matrix_p)\n",
        "      # featwinds_leaderboard.append(leaderboard_feats)\n",
        "    \n",
        "    # param_dict['featwinds_total'] = featwinds_total\n",
        "    # param_dict['featwinds_training'] = featwinds_training\n",
        "    # param_dict['featwinds_testing'] = featwinds_testing\n",
        "    # param_dict['featwinds_leaderboard'] = featwinds_leaderboard    \n",
        "    param_dict['R_total'] = R_total\n",
        "    param_dict['R_train'] = R_train\n",
        "    param_dict['R_test'] = R_test\n",
        "    param_dict['R_leaderboard'] = R_leaderboard\n",
        "    save_feature_parameters(filename)\n"
      ],
      "metadata": {
        "id": "TYPDWndiUaZO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3040e80-8ec0-441a-860f-6e1d8e44a12b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "previousRun.pkl uses the same parameters as currently set, so it will be loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split Training Data"
      ],
      "metadata": {
        "id": "wk3zokzc2oH2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CxYt7cfr2xe-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning Algorithms"
      ],
      "metadata": {
        "id": "AT3zJxIco_va"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qkP8WX_cpCuL"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}
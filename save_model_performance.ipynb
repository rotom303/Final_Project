{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rotom303/Final_Project/blob/main/save_model_performance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lX7G4GeJ03Mb"
      },
      "outputs": [],
      "source": [
        "#Set up the notebook environment\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import scipy\n",
        "import random\n",
        "from scipy.stats import pearsonr\n",
        "from scipy import signal as sig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6P2MDDm40ok4"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqF2y-mQ1sh1",
        "outputId": "94b0cff2-4013-44d2-bec5-fa9dbedb5fd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Penn/Spring 2023/BE 5210/Project/Part_2\n"
          ]
        }
      ],
      "source": [
        "#Your code here\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') \n",
        "\n",
        "%cd drive/MyDrive/Penn/'Spring 2023'/'BE 5210'/Project/Part_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lHs9FExc8iwO"
      },
      "outputs": [],
      "source": [
        "NUM_FINGERS = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pPmVJ98c1_Vg"
      },
      "outputs": [],
      "source": [
        "proj_data = scipy.io.loadmat('raw_training_data.mat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RANdzE6K2SMX"
      },
      "outputs": [],
      "source": [
        "#splitting into testing and training sets\n",
        "train_data_proportion = 0.7\n",
        "#patient 1\n",
        "\n",
        "random.seed(123)\n",
        "\n",
        "#glove\n",
        "total_p1_glove=proj_data['train_dg'][0][0]\n",
        "training_rows = list(range(0, int(len(total_p1_glove)*train_data_proportion)))\n",
        "training_p1_glove=total_p1_glove[training_rows,:] #60% of samples in training\n",
        "testing_p1_glove=np.delete(total_p1_glove, training_rows, axis=0) #40% of samples in testing\n",
        "\n",
        "#ecog\n",
        "total_p1_ecog=proj_data['train_ecog'][0][0]\n",
        "# total_p1_ecog=np.delete(total_p1_ecog, 54, 1)\n",
        "training_rows = list(range(0, int(len(total_p1_ecog)*train_data_proportion)))\n",
        "training_p1_ecog=total_p1_ecog[training_rows,:] #60% of samples in training\n",
        "testing_p1_ecog=np.delete(total_p1_ecog, training_rows, axis=0) #60% of samples in training\n",
        "\n",
        "#patient 2\n",
        "\n",
        "#glove\n",
        "total_p2_glove=proj_data['train_dg'][1][0]\n",
        "training_rows = list(range(0, int(len(total_p2_glove)*train_data_proportion)))\n",
        "training_p2_glove=total_p2_glove[training_rows,:] #60% of samples in training\n",
        "testing_p2_glove=np.delete(total_p2_glove, training_rows, axis=0) #60% of samples in training\n",
        "#ecog\n",
        "total_p2_ecog=proj_data['train_ecog'][1][0]\n",
        "# total_p2_ecog=np.delete(total_p2_ecog, [20, 37], 1)\n",
        "training_rows = list(range(0, int(len(total_p2_ecog)*train_data_proportion)))\n",
        "training_p2_ecog=total_p2_ecog[training_rows,:] #60% of samples in training\n",
        "testing_p2_ecog=np.delete(total_p2_ecog, training_rows, axis=0) #60% of samples in training\n",
        "\n",
        "#patient 3\n",
        "\n",
        "#glove\n",
        "total_p3_glove=proj_data['train_dg'][2][0]\n",
        "training_rows = list(range(0, int(len(total_p3_glove)*train_data_proportion)))\n",
        "training_p3_glove=total_p3_glove[training_rows,:] #60% of samples in training\n",
        "testing_p3_glove=np.delete(total_p3_glove, training_rows, axis=0) #60% of samples in training\n",
        "#ecog\n",
        "total_p3_ecog=proj_data['train_ecog'][2][0]\n",
        "training_rows = list(range(0, int(len(total_p3_ecog)*train_data_proportion)))\n",
        "training_p3_ecog=total_p3_ecog[training_rows,:] #60% of samples in training\n",
        "testing_p3_ecog=np.delete(total_p3_ecog, training_rows, axis=0) #60% of samples in training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6t_HhYhT2bYw"
      },
      "outputs": [],
      "source": [
        "def filter_data(raw_eeg, fs=1000, cutoffs=[75, 200]):\n",
        "  \"\"\"\n",
        "  Write a filter function to clean underlying data.\n",
        "  Filter type and parameters are up to you. Points will be awarded for reasonable filter type, parameters and application.\n",
        "  Please note there are many acceptable answers, but make sure you aren't throwing out crucial data or adversly\n",
        "  distorting the underlying data!\n",
        "\n",
        "  Input: \n",
        "    raw_eeg (samples x channels): the raw signal\n",
        "    fs: the sampling rate (1000 for this dataset)\n",
        "  Output: \n",
        "    clean_data (samples x channels): the filtered signal\n",
        "  \"\"\"\n",
        "  number_of_channels = np.shape(raw_eeg)[1] #number of channels\n",
        "  filteredData = np.zeros(np.shape(raw_eeg)); #filtered data output\n",
        "\n",
        "  #butterworth filter of 4th order\n",
        "  sos = sig.butter(4, cutoffs, 'bandpass', analog=False, fs=fs, output='sos'); # returns filter coefficients\n",
        "\n",
        "  #for each channel\n",
        "  for chanInd in np.arange(number_of_channels):\n",
        "    # subtract mean from each datapoint\n",
        "    currFilt = raw_eeg[:, chanInd] - np.mean(raw_eeg[:, chanInd]);\n",
        "    currFilt = sig.sosfiltfilt(sos, currFilt) # forward-backward digital filter using cascaded second-order sections                                \n",
        "    filteredData[:, chanInd] = currFilt\n",
        "  return filteredData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lw7v7GNu3GHG"
      },
      "outputs": [],
      "source": [
        "def NumWins(x, winLen, winDisp, fs):\n",
        "\n",
        "    # Calculate the length of the signal in samples\n",
        "    xLen = len(x)\n",
        "    # Calculate the number of windows\n",
        "    windows = ((len(x)/fs)/ winDisp) - (winLen / winDisp) + (winDisp / winDisp) - ((((len(x)/fs) - winLen + winDisp) % winDisp)/winDisp)\n",
        "    #windows = ((len(x)/fs)/ winDisp) - (winLen / winDisp) + (winDisp / winDisp)\n",
        "    return int(windows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "28b2S0L53d_b"
      },
      "outputs": [],
      "source": [
        "def line_length(signal):\n",
        "    return np.sum(np.absolute(np.ediff1d(signal))) \n",
        "\n",
        "def zero_crossings(x):\n",
        "  xbar=np.mean(x)\n",
        "  number_of_crossings = 0\n",
        "  for i in range(1,len(x)):\n",
        "    if (x[i-1]-xbar) > 0 and (x[i]-xbar) < 0:\n",
        "      number_of_crossings += 1\n",
        "    elif (x[i-1]-xbar) < 0 and (x[i]-xbar) > 0:\n",
        "      number_of_crossings += 1\n",
        "  return number_of_crossings\n",
        "\n",
        "def energy(signal):\n",
        "  return np.sum(np.square(signal))\n",
        "\n",
        "def area(signal):\n",
        "  return np.sum(np.absolute(signal))\n",
        "\n",
        "def time_avg(signal):\n",
        "  return np.mean(signal)\n",
        "\n",
        "from numpy.fft import fft, ifft\n",
        "\n",
        "def band_power(signal,fs,low,high):\n",
        "  X = fft(signal)\n",
        "  N = len(X)\n",
        "  n = np.arange(N)\n",
        "  T = N/fs #sampling rate=1000\n",
        "  freq = n/T \n",
        "  power_spectrum=np.abs(X)\n",
        "\n",
        "  # Find values in frequency vector corresponding to input band\n",
        "  index_band = np.logical_and(freq >= low, freq <= high)\n",
        "  #average frequency domain magnitude\n",
        "  avg_mag=np.mean(power_spectrum[index_band])\n",
        "\n",
        "  return avg_mag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Lu8sU0fs3kbZ"
      },
      "outputs": [],
      "source": [
        "def get_features(filtered_window, fs=1000):\n",
        "  \"\"\"\n",
        "    Write a function that calculates features for a given filtered window. \n",
        "    Feel free to use features you have seen before in this class, features that\n",
        "    have been used in the literature, or design your own!\n",
        "\n",
        "    Input: \n",
        "      filtered_window (window_samples x channels): the window of the filtered ecog signal \n",
        "      fs: sampling rate\n",
        "    Output:\n",
        "      features (channels x num_features): the features calculated on each channel for the window\n",
        "  \"\"\"\n",
        "  #print(np.shape(filtered_window))\n",
        "  [window_samples,num_channels]=np.shape(filtered_window)\n",
        "\n",
        "  features=np.empty((num_channels,5))\n",
        "\n",
        "  for cc in range(num_channels):\n",
        "\n",
        "    curr_window=filtered_window[:,cc] \n",
        "\n",
        "    #features[cc,0]=line_length(curr_window)\n",
        "    #features[cc,0]=area(curr_window)\n",
        "    features[cc,0]=energy(curr_window) # Energy in signal window\n",
        "    #features[cc,3]=zero_crossings(curr_window)\n",
        "    features[cc,1]=band_power(curr_window,1000,8,12) # average frequency-domain magnitude in alpha frequency band\n",
        "    features[cc,2]=band_power(curr_window,1000,75,95) # average frequency-domain magnitude in low gamma frequency band\n",
        "    features[cc,3]=band_power(curr_window,1000,96,115) # average frequency-domain magnitude in high gamma frequency band\n",
        "    features[cc,4]=time_avg(curr_window) #Average time-domain voltage\n",
        "\n",
        "  return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "P6eYlOsY3tp2"
      },
      "outputs": [],
      "source": [
        "def get_windowed_feats(raw_ecog, fs, window_length, window_overlap):\n",
        "  \"\"\"\n",
        "    Write a function which processes data through the steps of filtering and\n",
        "    feature calculation and returns features. Points will be awarded for completing\n",
        "    each step appropriately (note that if one of the functions you call within this script\n",
        "    returns a bad output, you won't be double penalized). Note that you will need\n",
        "    to run the filter_data and get_features functions within this function. \n",
        "\n",
        "    Inputs:\n",
        "      raw_eeg (samples x channels): the raw signal\n",
        "      fs: the sampling rate (1000 for this dataset)\n",
        "      window_length: the window's length\n",
        "      window_overlap: the window's overlap\n",
        "    Output: \n",
        "      all_feats (num_windows x (channels x features)): the features for each channel for each time window\n",
        "        note that this is a 2D array. \n",
        "  \"\"\"\n",
        "  clean_data=filter_data(raw_ecog, fs)\n",
        "  [num_samples,num_channels]=np.shape(clean_data)\n",
        "\n",
        "  num_windows = NumWins(clean_data[:,0], window_length,window_overlap, fs) #calculate number of windows and remaining time\n",
        "\n",
        "  #convert everything to units of samples\n",
        "  num_samples = len(clean_data)\n",
        "  winLen_samples=round(window_length*fs) #window length in samples\n",
        "  winDisp_samples=round(window_overlap*fs) #window displacement in samples\n",
        "  \n",
        "  # empty list to store features\n",
        "  feature_vector = []\n",
        "  # The end of the first window is the last sample\n",
        "  window_end = num_samples\n",
        "  # List to store tuples containing start and end indices for each slice\n",
        "\n",
        "  for i in range(round(num_windows)):\n",
        "\n",
        "    # Compute the start of the window using the end of the window\n",
        "    window_start = window_end - winLen_samples\n",
        "    # If the number of samples left is not sufficient, break out of the loop\n",
        "    if window_start < 0:\n",
        "        break\n",
        "    \n",
        "    signal_window=clean_data[window_start:window_end,:] #signal in that window\n",
        "    \n",
        "    # store feature of that window\n",
        "    feature_vector.append(get_features(signal_window, fs).flatten('F'))\n",
        "\n",
        "    #set new ending index of window\n",
        "    window_end -= winDisp_samples \n",
        "  \n",
        "  # Reverse at the end since we are looking at the windows backwards\n",
        "  feature_vector.reverse()\n",
        "\n",
        "\n",
        "  return feature_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Dzxb6-o83v60"
      },
      "outputs": [],
      "source": [
        "def create_R_matrix(features, N_wind):\n",
        "  \"\"\"\n",
        "  Write a function to calculate the R matrix\n",
        "\n",
        "  Input:\n",
        "    features (samples (number of windows in the signal) x channels x features): \n",
        "      the features you calculated using get_windowed_feats\n",
        "    N_wind: number of windows to use in the R matrix\n",
        "\n",
        "  Output:\n",
        "    R (samples x (N_wind*channels*features))\n",
        "  \"\"\"\n",
        "  padded_features = np.copy(features)\n",
        "  for i in list(range(N_wind-2, -1, -1)):\n",
        "      a = features[i]\n",
        "      padded_features = np.vstack([a, padded_features])\n",
        "  samples = len(features)   # number of rows = number of windows\n",
        "\n",
        "  R = np.zeros((samples, 1+(N_wind*len(features[0,:]))))  # len(features[0,:]) = (num of features)*(num of channels)\n",
        "  lst = np.array(list(range(1, 1+N_wind)))\n",
        "  R[:, 0] = 1\n",
        "\n",
        "  for i in range(len(features[0,:])):   # goes thru each column of the features matrix\n",
        "    for j in range(len(lst)):\n",
        "        x = lst[j]\n",
        "        R[:, x] = padded_features[j : (len(padded_features)-(N_wind-1-j)), i]\n",
        "    lst = lst + N_wind\n",
        "  return R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "971AMQdC8R-l"
      },
      "outputs": [],
      "source": [
        "def standardize_train_test(feature_matrix,test_feature_matrix):\n",
        "\n",
        "  [windows,feats]=np.shape(feature_matrix)\n",
        "  [windows_test,feats_test]=np.shape(test_feature_matrix)\n",
        "  normFeats=np.empty((windows,feats))\n",
        "  testnormFeats=np.empty((windows_test,feats_test))\n",
        "\n",
        "  for i in range(feats):\n",
        "      curr_train = feature_matrix[:,i]\n",
        "      mean_train=np.mean(curr_train)\n",
        "      std_train=np.std(curr_train)\n",
        "      normFeats[:,i]=(curr_train-mean_train)/std_train\n",
        "      curr_test = test_feature_matrix[:,i]\n",
        "      mean_test=np.mean(curr_test)\n",
        "      std_test=np.std(curr_test)\n",
        "      testnormFeats[:,i]=(curr_test-mean_train)/std_train #normalize test features using training mean/std\n",
        "\n",
        "  return normFeats,testnormFeats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mBNgQQHz6cMr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vXAWX2GG6wnb"
      },
      "outputs": [],
      "source": [
        "from numpy.linalg import inv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL2hkXAt6dpi"
      },
      "source": [
        "## Patient 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "V2Gr2GrX6cKE"
      },
      "outputs": [],
      "source": [
        "window_length=100e-3\n",
        "window_overlap=50e-3\n",
        "fs=1000\n",
        "\n",
        "#calculate features for training data, call it p1_trainFeats\n",
        "p1_trainFeats=get_windowed_feats(training_p1_ecog, fs, window_length, window_overlap)\n",
        "\n",
        "p1_trainFeats = np.array(p1_trainFeats)\n",
        "#calculate R for training data\n",
        "R_train=create_R_matrix(p1_trainFeats,3) #N=3\n",
        "\n",
        "\n",
        "#calculate Y for the training data\n",
        "\n",
        "M=NumWins(training_p1_glove[:,0],window_length,window_overlap, fs) #calculate number of windows and remaining time\n",
        "\n",
        "#convert everything to units of samples \n",
        "winLen_samples=round(window_length*fs) #window length in samples\n",
        "winDisp_samples=round(window_overlap*fs) #window displacement in samples \n",
        "\n",
        "# ensuring right alignment\n",
        "window_start_in_windows = round(len(training_p1_glove[:,0])/fs) - (M*window_overlap)\n",
        "window_start = round(window_start_in_windows*fs)\n",
        "\n",
        "Y_train_p1=np.empty([int(M),5])\n",
        "\n",
        "for i in range(round(M)): #for each window\n",
        "  Y_train_p1[i,:]=training_p1_glove[window_start,:] #find the flexion data for each finger at that window from glove data for P1\n",
        "  window_start=window_start+winDisp_samples #move to next window\n",
        "\n",
        "#calculate Y for the test data- basically flexion data downsampled to be Y=Mx5\n",
        "\n",
        "M=NumWins(testing_p1_glove[:,0],window_length,window_overlap, fs) #calculate number of windows and remaining time\n",
        "\n",
        "#convert everything to units of samples\n",
        "winLen_samples=round(window_length*fs) #window length in samples\n",
        "winDisp_samples=round(window_overlap*fs) #window displacement in samples \n",
        "\n",
        "#starting index of x- first window occurs after remainder samples since right aligned\n",
        "window_start_in_windows = round(len(testing_p1_glove[:,0])/fs) - (M*window_overlap)\n",
        "window_start = round(window_start_in_windows*fs)\n",
        "\n",
        "#initialize\n",
        "Y_test_p1=np.empty([int(M),5])\n",
        "\n",
        "for mm in range(round(M)): #for each window\n",
        "  Y_test_p1[mm,:]=testing_p1_glove[window_start,:] #find the flexion data for each finger at that window from glove data for P1\n",
        "  window_start=window_start+winDisp_samples #move to next window\n",
        "\n",
        "# Filter for subject 1\n",
        "f1=np.matmul(inv(np.matmul(np.transpose(R_train),R_train)),np.matmul(np.transpose(R_train),Y_train_p1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0PMnxm268Qh"
      },
      "source": [
        "## Patient 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TX8pLLqU66jG"
      },
      "outputs": [],
      "source": [
        "\n",
        "#calculate features for training data, call it p2_trainFeats\n",
        "p2_trainFeats = get_windowed_feats(training_p2_ecog, fs, window_length, window_overlap)\n",
        "\n",
        "p2_trainFeats = np.array(p2_trainFeats)\n",
        "R_train=create_R_matrix(p2_trainFeats,3) #N=3\n",
        "\n",
        "#calculate Y for the training data\n",
        "M=NumWins(training_p2_glove[:,0],window_length,window_overlap, fs) #calculate number of windows and remaining time\n",
        "\n",
        "#convert everything to units of samples \n",
        "winLen_samples=round(window_length*fs) #window length in samples\n",
        "winDisp_samples=round(window_overlap*fs) #window displacement in samples \n",
        "\n",
        "# ensuring right alignment\n",
        "window_start_in_windows = round(len(training_p2_glove[:,0])/fs) - (M*window_overlap)\n",
        "window_start = round(window_start_in_windows*fs)\n",
        "\n",
        "#initialize\n",
        "Y_train_p2=np.empty([int(M),5])\n",
        "\n",
        "for i in range(round(M)): #for each window\n",
        "  Y_train_p2[i,:]=training_p2_glove[window_start,:] #find the flexion data for each finger at that window from glove data for p2\n",
        "  window_start=window_start+winDisp_samples #move to next window\n",
        "\n",
        "#calculate Y for the test data- basically flexion data downsampled to be Y=Mx5\n",
        "\n",
        "M=NumWins(testing_p2_glove[:,0],window_length,window_overlap, fs) #calculate number of windows and remaining time\n",
        "\n",
        "winLen_samples=round(window_length*fs) #window length in samples\n",
        "winDisp_samples=round(window_overlap*fs) #window displacement in samples \n",
        "window_start_in_windows = round(len(testing_p2_glove[:,0])/fs) - (M*window_overlap)\n",
        "window_start = round(window_start_in_windows*fs)\n",
        "\n",
        "Y_test_p2=np.empty([int(M),5])\n",
        "\n",
        "for i in range(round(M)): #for each window\n",
        "  Y_test_p2[i,:]=testing_p2_glove[window_start,:] #find the flexion data for each finger at that window from glove data for p2\n",
        "  window_start=window_start+winDisp_samples #move to next window\n",
        "\n",
        "# Filter for subject 2\n",
        "f2=np.matmul(inv(np.matmul(np.transpose(R_train),R_train)),np.matmul(np.transpose(R_train),Y_train_p2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d83Vv8OW7Et0"
      },
      "source": [
        "## Patient 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ApfN5V_e6cHn"
      },
      "outputs": [],
      "source": [
        "\n",
        "#calculate features for training data, call it p3_trainFeats\n",
        "p3_trainFeats=get_windowed_feats(training_p3_ecog, fs, window_length, window_overlap)\n",
        "p3_trainFeats = np.array(p3_trainFeats)\n",
        "R_train=create_R_matrix(p3_trainFeats,3) #N=3\n",
        "\n",
        "\n",
        "#calculate Y for the training data\n",
        "M=NumWins(training_p3_glove[:,0],window_length,window_overlap, fs) #calculate number of windows\n",
        "\n",
        "winLen_samples=round(window_length*fs) #window length in samples\n",
        "winDisp_samples=round(window_overlap*fs) #window displacement in samples \n",
        "window_start_in_windows = round(len(training_p3_glove[:,0])/fs) - (M*window_overlap)\n",
        "window_start = round(window_start_in_windows*fs)\n",
        "\n",
        "Y_train_p3=np.empty([int(M),5])\n",
        "\n",
        "for i in range(round(M)): #for each window\n",
        "  Y_train_p3[i,:]=training_p3_glove[window_start,:] #find the flexion data for each finger at that window from glove data for p3\n",
        "  window_start=window_start+winDisp_samples #move to next window\n",
        "\n",
        "M=NumWins(testing_p3_glove[:,0],window_length,window_overlap, fs) #calculate number of windows\n",
        "\n",
        "#convert everything to units of samples\n",
        "winLen_samples=round(window_length*fs) #window length in samples\n",
        "winDisp_samples=round(window_overlap*fs) #window displacement in samples \n",
        "\n",
        "#starting index of x- first window occurs after remainder samples since right aligned\n",
        "window_start_in_windows = round(len(testing_p3_glove[:,0])/fs) - (M*window_overlap)\n",
        "window_start = round(window_start_in_windows*fs)\n",
        "\n",
        "#initialize\n",
        "Y_test_p3=np.empty([int(M),5])\n",
        "\n",
        "for i in range(round(M)): #for each window\n",
        "  Y_test_p3[i,:]=testing_p3_glove[window_start,:] #find the flexion data for each finger at that window from glove data for p3\n",
        "  window_start=window_start+winDisp_samples #move to next window\n",
        "\n",
        "# Filter for subject 3\n",
        "f3=np.matmul(inv(np.matmul(np.transpose(R_train),R_train)),np.matmul(np.transpose(R_train),Y_train_p3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "a8gz8Z8g7GPl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "xUWCBbgj7Ydl"
      },
      "outputs": [],
      "source": [
        "# Get the features on the testing data\n",
        "test_features_p1 = get_windowed_feats(testing_p1_ecog, fs, window_length, window_overlap)\n",
        "test_features_p2 = get_windowed_feats(testing_p2_ecog, fs, window_length, window_overlap)\n",
        "test_features_p3 = get_windowed_feats(testing_p3_ecog, fs, window_length, window_overlap)\n",
        "test_features_p1 = np.array(test_features_p1)\n",
        "test_features_p2 = np.array(test_features_p2)\n",
        "test_features_p3 = np.array(test_features_p3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5yQKACW8VyU"
      },
      "source": [
        "### Standardize All Data + Create R Matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "oxIv3jwo7YU4"
      },
      "outputs": [],
      "source": [
        "normalized_train_p1,normalized_test_p1 = standardize_train_test(p1_trainFeats,test_features_p1)\n",
        "normalized_train_p2,normalized_test_p2 = standardize_train_test(p2_trainFeats,test_features_p2)\n",
        "normalized_train_p3,normalized_test_p3 = standardize_train_test(p3_trainFeats,test_features_p3)\n",
        "R_train1 = create_R_matrix(normalized_train_p1,3)\n",
        "R_train2 = create_R_matrix(normalized_train_p2,3)\n",
        "R_train3 = create_R_matrix(normalized_train_p3,3)\n",
        "R_test1 = create_R_matrix(normalized_test_p1,3)\n",
        "R_test2 = create_R_matrix(normalized_test_p2,3)\n",
        "R_test3 = create_R_matrix(normalized_test_p3,3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z__NJEB39ll2"
      },
      "source": [
        "## Linear Filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC7Pxg8p6DRv",
        "outputId": "4067e8fb-c14b-45bb-c35a-b612df1ca86c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correlation coefficient for Patient 1 Finger 1: 0.39522317328756623\n",
            "Correlation coefficient for Patient 1 Finger 2: 0.5379127158873067\n",
            "Correlation coefficient for Patient 1 Finger 3: 0.0868640600732274\n",
            "Correlation coefficient for Patient 1 Finger 5: 0.11308621355032815\n",
            "Average Correlation coefficient for Patient 1: 0.2832715406996071\n"
          ]
        }
      ],
      "source": [
        "R_test_1=create_R_matrix(test_features_p1,3) \n",
        "pred_finger_lf_p1=np.matmul(R_test_1,f1)\n",
        "\n",
        "p1_corr_finger1=pearsonr(pred_finger_lf_p1[:,0], Y_test_p1[:,0])\n",
        "p1_corr_finger2=pearsonr(pred_finger_lf_p1[:,1], Y_test_p1[:,1])\n",
        "p1_corr_finger3=pearsonr(pred_finger_lf_p1[:,2], Y_test_p1[:,2])\n",
        "#p1_corr_finger4=pearsonr(pred_finger_lf_p1[:,3], Y_test_p1[:,3])\n",
        "p1_corr_finger5=pearsonr(pred_finger_lf_p1[:,4], Y_test_p1[:,4])\n",
        "\n",
        "print(\"Correlation coefficient for Patient 1 Finger 1:\",p1_corr_finger1.statistic)\n",
        "print(\"Correlation coefficient for Patient 1 Finger 2:\",p1_corr_finger2.statistic)\n",
        "print(\"Correlation coefficient for Patient 1 Finger 3:\",p1_corr_finger3.statistic)\n",
        "#print(\"Correlation coefficient for Patient 1 Finger 4:\",p1_corr_finger4.statistic)\n",
        "print(\"Correlation coefficient for Patient 1 Finger 5:\",p1_corr_finger5.statistic)\n",
        "avg_corr_coeff = (p1_corr_finger1.statistic + p1_corr_finger2.statistic + p1_corr_finger3.statistic + p1_corr_finger5.statistic)/4\n",
        "print(\"Average Correlation coefficient for Patient 1:\",avg_corr_coeff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjgqiEGYJJ4u",
        "outputId": "7757b14b-5fcc-4d8a-ac68-bc5397680ff6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correlation coefficient for Patient 2 Finger 1: 0.38147861257849297\n",
            "Correlation coefficient for Patient 2 Finger 2: 0.22599780076781756\n",
            "Correlation coefficient for Patient 2 Finger 3: 0.14232231800135578\n",
            "Correlation coefficient for Patient 2 Finger 4: 0.439253419706396\n",
            "Correlation coefficient for Patient 2 Finger 5: 0.24842322162033934\n"
          ]
        }
      ],
      "source": [
        "R_test_2=create_R_matrix(test_features_p2,3) \n",
        "pred_finger_lf_p2=np.matmul(R_test_2,f2)\n",
        "\n",
        "p2_corr_finger1=pearsonr(pred_finger_lf_p2[:,0], Y_test_p2[:,0])\n",
        "p2_corr_finger2=pearsonr(pred_finger_lf_p2[:,1], Y_test_p2[:,1])\n",
        "p2_corr_finger3=pearsonr(pred_finger_lf_p2[:,2], Y_test_p2[:,2])\n",
        "p2_corr_finger4=pearsonr(pred_finger_lf_p2[:,3], Y_test_p2[:,3])\n",
        "p2_corr_finger5=pearsonr(pred_finger_lf_p2[:,4], Y_test_p2[:,4])\n",
        "\n",
        "print(\"Correlation coefficient for Patient 2 Finger 1:\",p2_corr_finger1.statistic)\n",
        "print(\"Correlation coefficient for Patient 2 Finger 2:\",p2_corr_finger2.statistic)\n",
        "print(\"Correlation coefficient for Patient 2 Finger 3:\",p2_corr_finger3.statistic)\n",
        "print(\"Correlation coefficient for Patient 2 Finger 4:\",p2_corr_finger4.statistic)\n",
        "print(\"Correlation coefficient for Patient 2 Finger 5:\",p2_corr_finger5.statistic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BMb0grg9ogj"
      },
      "source": [
        "## SVR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24Kit29S8Lt2"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "regressor = SVR(kernel = 'rbf')\n",
        "\n",
        "svr_pred_p1 = np.zeros((len(R_test1), NUM_FINGERS))\n",
        "corr_list_p1 = []\n",
        "\n",
        "for i in range(5):\n",
        "  svr1=regressor.fit(R_train1,Y_train_p1[:,i])\n",
        "  svr_pred_p1[:,i] = svr1.predict(R_test1)\n",
        "  print(\"Correlation of angles for finger\",(i+1),\":\",  pearsonr(svr_pred_p1[:, i], Y_test_p1[:, i]).statistic)\n",
        "  corr_list_p1.append(pearsonr(svr_pred_p1[:, i], Y_test_p1[:, i]).statistic)\n",
        "\n",
        "print(\"Average coefficient:\", (corr_list_p1[0] + corr_list_p1[1] + corr_list_p1[2] + corr_list_p1[4])/4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65zikPIc8Lrx"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "regressor = SVR(kernel = 'rbf')\n",
        "\n",
        "svr_pred_p2 = np.zeros((len(R_test2), NUM_FINGERS))\n",
        "corr_list_p2 = []\n",
        "\n",
        "for i in range(5):\n",
        "  svr2=regressor.fit(R_train2,Y_train_p2[:,i])\n",
        "  svr_pred_p2[:,i] = svr2.predict(R_test2)\n",
        "  print(\"Correlation of angles for finger\",(i+1),\":\",  pearsonr(svr_pred_p2[:, i], Y_test_p2[:, i]).statistic)\n",
        "  corr_list_p2.append(pearsonr(svr_pred_p2[:, i], Y_test_p2[:, i]).statistic)\n",
        "\n",
        "print(\"Average coefficient:\", (corr_list_p2[0] + corr_list_p2[1] + corr_list_p2[2] + corr_list_p2[4])/4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRhJ_If58LmR"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "regressor = SVR(kernel = 'rbf')\n",
        "\n",
        "svr_pred_p3 = np.zeros((len(R_test3), NUM_FINGERS))\n",
        "corr_list_p3 = []\n",
        "\n",
        "for i in range(5):\n",
        "  svr3=regressor.fit(R_train3,Y_train_p3[:,i])\n",
        "  svr_pred_p3[:,i] = svr3.predict(R_test3)\n",
        "  print(\"Correlation of angles for finger\",(i+1),\":\",  pearsonr(svr_pred_p3[:, i], Y_test_p3[:, i]).statistic)\n",
        "  corr_list_p3.append(pearsonr(svr_pred_p3[:, i], Y_test_p3[:, i]).statistic)\n",
        "\n",
        "print(\"Average coefficient:\", (corr_list_p3[0] + corr_list_p3[1] + corr_list_p3[2] + corr_list_p3[4])/4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3Yd_m3mAmtW"
      },
      "source": [
        "## Fit All Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "az6OQo89JcPD"
      },
      "outputs": [],
      "source": [
        "def smooth(input, smoothSize):\n",
        "  convThing = sig.gaussian(smoothSize, 3)/smoothSize;\n",
        "  return np.convolve(input, convThing, mode='same')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jK_b_KUGAoWm"
      },
      "outputs": [],
      "source": [
        "p1_f1 = SVR(kernel = 'rbf').fit(R_train1, Y_train_p1[:,0])\n",
        "p1_f2 = SVR(kernel = 'rbf').fit(R_train1, Y_train_p1[:,1])\n",
        "p1_f3 = SVR(kernel = 'rbf').fit(R_train1, Y_train_p1[:,2])\n",
        "p1_f4 = SVR(kernel = 'rbf').fit(R_train1, Y_train_p1[:,3])\n",
        "p1_f5 = SVR(kernel = 'rbf').fit(R_train1, Y_train_p1[:,4])\n",
        "\n",
        "p2_f1 = SVR(kernel = 'rbf').fit(R_train2, Y_train_p2[:,0])\n",
        "p2_f2 = SVR(kernel = 'rbf').fit(R_train2, Y_train_p2[:,1])\n",
        "p2_f3 = SVR(kernel = 'rbf').fit(R_train2, Y_train_p2[:,2])\n",
        "p2_f4 = SVR(kernel = 'rbf').fit(R_train2, Y_train_p2[:,3])\n",
        "p2_f5 = SVR(kernel = 'rbf').fit(R_train2, Y_train_p2[:,4])\n",
        "\n",
        "p3_f1 = SVR(kernel = 'rbf').fit(R_train3, Y_train_p3[:,0])\n",
        "p3_f2 = SVR(kernel = 'rbf').fit(R_train3, Y_train_p3[:,1])\n",
        "p3_f3 = SVR(kernel = 'rbf').fit(R_train3, Y_train_p3[:,2])\n",
        "p3_f4 = SVR(kernel = 'rbf').fit(R_train3, Y_train_p3[:,3])\n",
        "p3_f5 = SVR(kernel = 'rbf').fit(R_train3, Y_train_p3[:,4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5JakYBqCS8s"
      },
      "outputs": [],
      "source": [
        "model_list = [[p1_f1, p1_f2, p1_f3, p1_f4, p1_f5],\n",
        "              [p2_f1, p2_f2, p2_f3, p2_f4, p2_f5],\n",
        "              [p3_f1, p3_f2, p3_f3, p3_f4, p3_f5]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMldNno4FQxS"
      },
      "source": [
        "## Retrain models on the entire dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHXKB_ncFSwn"
      },
      "outputs": [],
      "source": [
        "# Get all R matrices\n",
        "# Testing data here needs to be replaced with the leaderboard data\n",
        "\n",
        "p1_allFeats = get_windowed_feats(total_p1_ecog, fs, window_length, window_overlap)\n",
        "p1_allFeats = np.array(p1_allFeats)\n",
        "\n",
        "p2_allFeats = get_windowed_feats(total_p2_ecog, fs, window_length, window_overlap)\n",
        "p2_allFeats = np.array(p2_allFeats)\n",
        "\n",
        "p3_allFeats = get_windowed_feats(total_p3_ecog, fs, window_length, window_overlap)\n",
        "p3_allFeats = np.array(p3_allFeats)\n",
        "\n",
        "p1_normalized_all, p1_normalized_test = standardize_train_test(p1_allFeats, test_features_p1)\n",
        "p2_normalized_all, p2_normalized_test = standardize_train_test(p2_allFeats, test_features_p2)\n",
        "p3_normalized_all, p3_normalized_test = standardize_train_test(p3_allFeats, test_features_p3)\n",
        "\n",
        "R_p1 = create_R_matrix(p1_normalized_all,3)\n",
        "R_p2 = create_R_matrix(p2_normalized_all,3)\n",
        "R_p3 = create_R_matrix(p3_normalized_all,3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWNcHmP3LpiF"
      },
      "outputs": [],
      "source": [
        "# Get all downsampled Y matrices\n",
        "\n",
        "# Patient 1\n",
        "\n",
        "M=NumWins(total_p1_glove[:,0],window_length,window_overlap,fs) #calculate number of windows and remaining time\n",
        "winLen_samples=round(window_length*fs) #window length in samples\n",
        "winDisp_samples=round(window_overlap*fs) #window displacement in samples \n",
        "window_start_in_windows = round(len(total_p1_glove[:,0])/fs) - (M*window_overlap)\n",
        "window_start = round(window_start_in_windows*fs)\n",
        "Y_p1=np.empty([int(M),5])\n",
        "for mm in range(round(M)): #for each window\n",
        "  Y_p1[mm,:]=total_p1_glove[window_start,:] #find the flexion data for each finger at that window from glove data for P1\n",
        "  window_start=window_start+winDisp_samples #move to next window\n",
        "\n",
        "# Patient 2\n",
        "\n",
        "M=NumWins(total_p2_glove[:,0],window_length,window_overlap,fs) #calculate number of windows and remaining time\n",
        "winLen_samples=round(window_length*fs) #window length in samples\n",
        "winDisp_samples=round(window_overlap*fs) #window displacement in samples \n",
        "window_start_in_windows = round(len(total_p2_glove[:,0])/fs) - (M*window_overlap)\n",
        "window_start = round(window_start_in_windows*fs)\n",
        "Y_p2=np.empty([int(M),5])\n",
        "for mm in range(round(M)): #for each window\n",
        "  Y_p2[mm,:]=total_p2_glove[window_start,:] #find the flexion data for each finger at that window from glove data for P1\n",
        "  window_start=window_start+winDisp_samples #move to next window\n",
        "\n",
        "# Patient 3\n",
        "\n",
        "M=NumWins(total_p3_glove[:,0],window_length,window_overlap,fs) #calculate number of windows and remaining time\n",
        "winLen_samples=round(window_length*fs) #window length in samples\n",
        "winDisp_samples=round(window_overlap*fs) #window displacement in samples \n",
        "window_start_in_windows = round(len(total_p3_glove[:,0])/fs) - (M*window_overlap)\n",
        "window_start = round(window_start_in_windows*fs)\n",
        "Y_p3=np.empty([int(M),5])\n",
        "for mm in range(round(M)): #for each window\n",
        "  Y_p3[mm,:]=total_p3_glove[window_start,:] #find the flexion data for each finger at that window from glove data for P1\n",
        "  window_start=window_start+winDisp_samples #move to next window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaQA_mxWKuZp"
      },
      "outputs": [],
      "source": [
        "fin_p1_f1 = SVR(kernel = 'rbf').fit(R_p1, Y_p1[:,0])\n",
        "fin_p1_f2 = SVR(kernel = 'rbf').fit(R_p1, Y_p1[:,1])\n",
        "fin_p1_f3 = SVR(kernel = 'rbf').fit(R_p1, Y_p1[:,2])\n",
        "fin_p1_f4 = SVR(kernel = 'rbf').fit(R_p1, Y_p1[:,3])\n",
        "fin_p1_f5 = SVR(kernel = 'rbf').fit(R_p1, Y_p1[:,4])\n",
        "\n",
        "fin_p2_f1 = SVR(kernel = 'rbf').fit(R_p2, Y_p2[:,0])\n",
        "fin_p2_f2 = SVR(kernel = 'rbf').fit(R_p2, Y_p2[:,1])\n",
        "fin_p2_f3 = SVR(kernel = 'rbf').fit(R_p2, Y_p2[:,2])\n",
        "fin_p2_f4 = SVR(kernel = 'rbf').fit(R_p2, Y_p2[:,3])\n",
        "fin_p2_f5 = SVR(kernel = 'rbf').fit(R_p2, Y_p2[:,4])\n",
        "\n",
        "fin_p3_f1 = SVR(kernel = 'rbf').fit(R_p3, Y_p3[:,0])\n",
        "fin_p3_f2 = SVR(kernel = 'rbf').fit(R_p3, Y_p3[:,1])\n",
        "fin_p3_f3 = SVR(kernel = 'rbf').fit(R_p3, Y_p3[:,2])\n",
        "fin_p3_f4 = SVR(kernel = 'rbf').fit(R_p3, Y_p3[:,3])\n",
        "fin_p3_f5 = SVR(kernel = 'rbf').fit(R_p3, Y_p3[:,4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clXsFXI_NlWj"
      },
      "outputs": [],
      "source": [
        "fin_model_list = [[fin_p1_f1, fin_p1_f2, fin_p1_f3, fin_p1_f4, fin_p1_f5],\n",
        "              [fin_p2_f1, fin_p2_f2, fin_p2_f3, fin_p2_f4, fin_p2_f5],\n",
        "              [fin_p3_f1, fin_p3_f2, fin_p3_f3, fin_p3_f4, fin_p3_f5]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYNN2j-EOG-y"
      },
      "source": [
        "Testing the final models on the testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoFYbVLfNqha",
        "outputId": "46a4b74e-64ca-4904-d65e-1122496e0122"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correlation of angles for person 1 finger 1 : 0.8582817597111746\n",
            "Correlation of angles for person 1 finger 2 : 0.8877865459213632\n",
            "Correlation of angles for person 1 finger 3 : 0.7686568010695028\n",
            "Correlation of angles for person 1 finger 5 : 0.7358923569784116\n",
            "Correlation of angles for person 2 finger 1 : 0.8799575434725827\n",
            "Correlation of angles for person 2 finger 2 : 0.7765502333290292\n",
            "Correlation of angles for person 2 finger 3 : 0.8464354404636952\n",
            "Correlation of angles for person 2 finger 5 : 0.797079094552236\n",
            "Correlation of angles for person 3 finger 1 : 0.9472175372005719\n",
            "Correlation of angles for person 3 finger 2 : 0.9653608669366407\n",
            "Correlation of angles for person 3 finger 3 : 0.9554724507629795\n",
            "Correlation of angles for person 3 finger 5 : 0.9126170913696716\n",
            "Average Coefficient: 0.8609423101473217\n"
          ]
        }
      ],
      "source": [
        "fin_corr_list = []\n",
        "for i in range(len(fin_model_list)):\n",
        "    for j in range(len(fin_model_list[i])):\n",
        "        curr_model = fin_model_list[i][j]\n",
        "        x_test = R_test1\n",
        "        y_test = Y_test_p1\n",
        "        if i == 1:\n",
        "            x_test = R_test2\n",
        "            y_test = Y_test_p2\n",
        "        if i == 2:\n",
        "            x_test = R_test3\n",
        "            y_test = Y_test_p3\n",
        "        \n",
        "        preds = curr_model.predict(x_test)\n",
        "        #preds = smooth(preds,22)\n",
        "        #print(preds.shape)\n",
        "        #print(Y_test_p3.shape)\n",
        "        if j != 3:\n",
        "            print(\"Correlation of angles for person\", (i+1), \"finger\",(j+1),\":\",  pearsonr(preds, y_test[:, j]).statistic)\n",
        "            fin_corr_list.append(pearsonr(preds, y_test[:, j]).statistic)\n",
        "\n",
        "print(\"Average Coefficient:\", sum(fin_corr_list)/len(fin_corr_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOcHIG4j8MQb"
      },
      "source": [
        "## Leaderboard Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Q9-16NGMhzdI"
      },
      "outputs": [],
      "source": [
        "def zoInterp(x, numInterp):\n",
        "  repeat=np.tile(x[0],numInterp)\n",
        "  interpolation_x=repeat\n",
        "  for p in range(1,len(x)):\n",
        "    repeat=np.tile(x[p],numInterp)\n",
        "    interpolation_x=np.hstack((interpolation_x,repeat))\n",
        "  return interpolation_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pg4Twimd87i"
      },
      "outputs": [],
      "source": [
        "# Get leaderboard data\n",
        "leaderboard_data = scipy.io.loadmat('leaderboard_data.mat')\n",
        "p1_leaderboard_ecog=leaderboard_data['leaderboard_ecog'][0][0]\n",
        "p2_leaderboard_ecog=leaderboard_data['leaderboard_ecog'][1][0]\n",
        "p3_leaderboard_ecog=leaderboard_data['leaderboard_ecog'][2][0]\n",
        "p1_ecog=p1_leaderboard_ecog[:,np.arange(62)!=54] #remove channel 55\n",
        "p2_ecog=p2_leaderboard_ecog[:,np.logical_and(np.arange(48)!=20,np.arange(48)!=37)] #remove channel 21 and 38\n",
        "p3_ecog=p3_leaderboard_ecog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7UEjgc9d6-8"
      },
      "outputs": [],
      "source": [
        "# Get features from leaderboard data\n",
        "\n",
        "p1_Feats_l=get_windowed_feats(p1_leaderboard_ecog, fs, window_length, window_overlap)\n",
        "p2_Feats_l=get_windowed_feats(p2_leaderboard_ecog, fs, window_length, window_overlap)\n",
        "p3_Feats_l=get_windowed_feats(p3_leaderboard_ecog, fs, window_length, window_overlap)\n",
        "p1_Feats_l=np.array(p1_Feats_l)\n",
        "p2_Feats_l=np.array(p2_Feats_l)\n",
        "p3_Feats_l=np.array(p3_Feats_l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCGOKDB7eVqw"
      },
      "outputs": [],
      "source": [
        "# Standardize the training and leaderboard data\n",
        "\n",
        "p1_normalized_all, p1_normalized_leader = standardize_train_test(p1_allFeats, p1_Feats_l)\n",
        "p2_normalized_all, p2_normalized_leader = standardize_train_test(p2_allFeats, p2_Feats_l)\n",
        "p3_normalized_all, p3_normalized_leader = standardize_train_test(p3_allFeats, p3_Feats_l)\n",
        "R_p1_leader=create_R_matrix(p1_normalized_leader,3) #N=3\n",
        "R_p2_leader=create_R_matrix(p2_normalized_leader,3) #N=3\n",
        "R_p3_leader=create_R_matrix(p3_normalized_leader,3) #N=3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqn1cX9veDyG"
      },
      "outputs": [],
      "source": [
        "samples,channels=np.shape(p1_leaderboard_ecog)\n",
        "leaderboard_pred_3=np.zeros((samples, NUM_FINGERS))\n",
        "leaderboard_pred_2=np.zeros((samples, NUM_FINGERS))\n",
        "leaderboard_pred_1=np.zeros((samples, NUM_FINGERS))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiV3dN70VqSL"
      },
      "outputs": [],
      "source": [
        "total_samples = 147500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHT7k1V78Lj5"
      },
      "outputs": [],
      "source": [
        "for i in range(5):\n",
        "    print(\"i =\", i)\n",
        "    # Patient 1\n",
        "    y_pred_test3 = fin_model_list[2][i].predict(R_p3_leader)\n",
        "    smoothed3=smooth(y_pred_test3,20)\n",
        "    interpAngle3=zoInterp(smoothed3,winDisp_samples)\n",
        "    padding3=np.tile(interpAngle3[0],total_samples - len(interpAngle3))\n",
        "    totalPrediction3=np.transpose(np.hstack((padding3,interpAngle3)))\n",
        "    leaderboard_pred_3[:,i]=totalPrediction3\n",
        "    # Patient 2\n",
        "    y_pred_test2 = fin_model_list[1][i].predict(R_p2_leader)\n",
        "    smoothed2=smooth(y_pred_test2,20)\n",
        "\n",
        "    # interpolate the prediction finger angles for this finger/patient\n",
        "    interpAngle2=zoInterp(smoothed2,winDisp_samples)\n",
        "    padding2=np.tile(interpAngle2[0],total_samples - len(interpAngle2))\n",
        "    totalPrediction2=np.transpose(np.hstack((padding2,interpAngle2)))\n",
        "    # add to prediction array\n",
        "    leaderboard_pred_2[:,i]=totalPrediction2\n",
        "\n",
        "    # Patient 1\n",
        "    y_pred_test1 = fin_model_list[0][i].predict(R_p1_leader)\n",
        "    smoothed1=smooth(y_pred_test1,20)\n",
        "    # interpolate the prediction finger angles for this finger/patient\n",
        "    interpAngle1=zoInterp(smoothed1,winDisp_samples)\n",
        "    padding1=np.tile(interpAngle1[0],total_samples - len(interpAngle1))\n",
        "    totalPrediction1=np.transpose(np.hstack((padding1,interpAngle1)))\n",
        "    leaderboard_pred_1[:,i]=totalPrediction1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJBpBnMhjlTC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.io import savemat\n",
        "\n",
        "predictions = np.zeros((3,1), dtype=object)\n",
        "predictions[0,0] = leaderboard_pred_1\n",
        "predictions[1,0] = leaderboard_pred_2\n",
        "predictions[2,0] = leaderboard_pred_3\n",
        "\n",
        "#save the array using the right format\n",
        "savemat('predictions.mat', {'predicted_dg':predictions})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wobbH7HttaX6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "vXvEN-X3tooP"
      },
      "outputs": [],
      "source": [
        "# model_list should be a 3x5 list where the ith row contains the 5 models for person i\n",
        "def save_model_performance(model_list, R_test_p1, R_test_p2, R_test_p3, Y_test_p1, Y_test_p2, Y_test_p3):\n",
        "    worksheet = gc.open('model_performance').sheet1\n",
        "    rows = worksheet.get_all_values()\n",
        "    df = pd.DataFrame.from_records(rows[1:],columns=rows[0])\n",
        "    df = df.set_index('index')\n",
        "    performance_dict = df.to_dict(orient='index')\n",
        "    \n",
        "    for i in range(len(model_list)):\n",
        "        for j in range(len(model_list[i])):\n",
        "            curr_model = model_list[i][j]\n",
        "            x_test = R_test_p1\n",
        "            y_test = Y_test_p1\n",
        "            if i == 1:\n",
        "                x_test = R_test_p2\n",
        "                y_test = Y_test_p2\n",
        "            if i == 2:\n",
        "                x_test = R_test3\n",
        "                y_test = Y_test_p3\n",
        "            \n",
        "            preds = curr_model.predict(x_test)\n",
        "            preds = smooth(preds,20)\n",
        "\n",
        "            model_type = type(curr_model).__name__\n",
        "            this_correlation = pearsonr(preds, y_test[:, j]).statistic\n",
        "            print(\"Correlation of angles for person\", (i+1), \"finger\",(j+1),\":\",  this_correlation)\n",
        "            pf_string = \"p\"+str(i+1)+\"_f\"+str(j+1)\n",
        "            check_curr_performance = performance_dict[pf_string].get(model_type)\n",
        "            if check_curr_performance == None:\n",
        "                performance_dict[pf_string][model_type] = this_correlation\n",
        "            elif this_correlation > float(check_curr_performance):\n",
        "                performance_dict[pf_string][model_type] = this_correlation\n",
        "            \n",
        "    new_df = pd.DataFrame.from_dict(performance_dict, orient='index').reset_index()\n",
        "    #print(new_df)\n",
        "    worksheet.clear()\n",
        "    worksheet.update([new_df.columns.values.tolist()] + new_df.values.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNEGkBscyeVA",
        "outputId": "324b8c7b-8a8a-4871-a56e-884a3d74ade1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correlation of angles for person 1 finger 1 : 0.4578840509308103\n",
            "Correlation of angles for person 1 finger 2 : 0.6482243426445566\n",
            "Correlation of angles for person 1 finger 3 : 0.17355239774957038\n",
            "Correlation of angles for person 1 finger 4 : 0.6136511046468438\n",
            "Correlation of angles for person 1 finger 5 : 0.13735723635140382\n",
            "Correlation of angles for person 2 finger 1 : 0.5630514066804939\n",
            "Correlation of angles for person 2 finger 2 : 0.31863640962460343\n",
            "Correlation of angles for person 2 finger 3 : 0.1828570023163079\n",
            "Correlation of angles for person 2 finger 4 : 0.4495373723282318\n",
            "Correlation of angles for person 2 finger 5 : 0.24262842383954383\n",
            "Correlation of angles for person 3 finger 1 : 0.6425943062617031\n",
            "Correlation of angles for person 3 finger 2 : 0.42272006197932477\n",
            "Correlation of angles for person 3 finger 3 : 0.5079300108264427\n",
            "Correlation of angles for person 3 finger 4 : 0.5336101422814172\n",
            "Correlation of angles for person 3 finger 5 : 0.5198669310815073\n"
          ]
        }
      ],
      "source": [
        "save_model_performance(model_list,R_test1,R_test2, R_test3, Y_test_p1, Y_test_p2, Y_test_p3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "\"n_estimators\": 75, #25 and 100 came out to be lower \n",
        "\"max_depth\": 3, #4 doesnt improve\n",
        "\"learning_rate\": 0.1, #could try changing this \n",
        "\"random_state\": 0\n",
        "}"
      ],
      "metadata": {
        "id": "Zi3nrSqNJT5C"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXwIsTAc8nNr"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from xgboost.sklearn import XGBRegressor\n",
        "\n",
        "gbr_p1_f1 = XGBRegressor(**params).fit(R_train1, Y_train_p1[:,0])\n",
        "gbr_p1_f2 = XGBRegressor(**params).fit(R_train1, Y_train_p1[:,1])\n",
        "gbr_p1_f3 = XGBRegressor(**params).fit(R_train1, Y_train_p1[:,2])\n",
        "gbr_p1_f4 = XGBRegressor(**params).fit(R_train1, Y_train_p1[:,3])\n",
        "gbr_p1_f5 = XGBRegressor(**params).fit(R_train1, Y_train_p1[:,4])\n",
        "\n",
        "gbr_p2_f1 = XGBRegressor(**params).fit(R_train2, Y_train_p2[:,0])\n",
        "gbr_p2_f2 = XGBRegressor(**params).fit(R_train2, Y_train_p2[:,1])\n",
        "gbr_p2_f3 = XGBRegressor(**params).fit(R_train2, Y_train_p2[:,2])\n",
        "gbr_p2_f4 = XGBRegressor(**params).fit(R_train2, Y_train_p2[:,3])\n",
        "gbr_p2_f5 = XGBRegressor(**params).fit(R_train2, Y_train_p2[:,4])\n",
        "\n",
        "gbr_p3_f1 = XGBRegressor(**params).fit(R_train3, Y_train_p3[:,0])\n",
        "gbr_p3_f2 = XGBRegressor(**params).fit(R_train3, Y_train_p3[:,1])\n",
        "gbr_p3_f3 = XGBRegressor(**params).fit(R_train3, Y_train_p3[:,2])\n",
        "gbr_p3_f4 = XGBRegressor(**params).fit(R_train3, Y_train_p3[:,3])\n",
        "gbr_p3_f5 = XGBRegressor(**params).fit(R_train3, Y_train_p3[:,4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7uiKn-O--Fv"
      },
      "outputs": [],
      "source": [
        "gbr_model_list = [[gbr_p1_f1, gbr_p1_f2, gbr_p1_f3, gbr_p1_f4, gbr_p1_f5],\n",
        "              [gbr_p2_f1, gbr_p2_f2, gbr_p2_f3, gbr_p2_f4, gbr_p2_f5],\n",
        "              [gbr_p3_f1, gbr_p3_f2, gbr_p3_f3, gbr_p3_f4, gbr_p3_f5]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ah2NEL__GOY"
      },
      "outputs": [],
      "source": [
        "save_model_performance(gbr_model_list,R_test1,R_test2, R_test3, Y_test_p1, Y_test_p2, Y_test_p3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xg4MhOT0_JmD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnJ5qnMctvspxUkygGZK7s",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}